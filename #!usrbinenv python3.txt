#!/usr/bin/env python3
'''
Raspberry Pi Smart Lighting System with Computer Vision and Telegram Control
- Detects people using MediaPipe Pose detection
- Detects motion using background subtraction
- Controls lights via GPIO pins
- Can be controlled remotely via Telegram bot
- Supports automatic and manual modes
'''

import os
from picamera2 import Picamera2
from picamera2.encoders import JpegEncoder
from picamera2.outputs import FileOutput
import cv2
import numpy as np
import mediapipe as mp
import time
from datetime import datetime
from collections import deque
import RPi.GPIO as GPIO
import asyncio
import threading
import io
import logging
import signal
import sys
import traceback
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes, MessageHandler, filters
from scipy.optimize import linear_sum_assignment


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("smart_lighting.log")
    ]
)
logger = logging.getLogger(__name__)

# Suppress TensorFlow warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Initialize MediaPipe components
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# Constants Configuration
class Config:
    TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN", "7317408065:AAHHxKcQEJiPL_PWluwyp003xOA_WNQIydI")  # Your bot token from BotFather
    ALLOWED_CHAT_IDS = []  # Empty = allow all chats
    DEBUG_MODE = True
    RELAY_PIN_1 = 17
    RELAY_PIN_2 = 18
    SWITCH_PIN = 23
    LED_PIN = 24
    AUTO_LIGHT_TIMEOUT = 5 # Increased from 5 to 10 seconds
    NOTIFICATION_COOLDOWN = 60
    MAX_DISAPPEARED = 15  # Maximum frames a person can disappear before tracking is lost
    MAX_DISTANCE = 50  # Maximum distance for tracking between frames
    HISTORY_LENGTH = 20  # Number of position history points to keep for visualization
    MOTION_MIN_AREA = 6000  # Increased from 3000 to 6000 to reduce false positives
    PERSON_CONFIDENCE_THRESHOLD = 0.8  # Minimum confidence for person detection
    MOTION_COOLDOWN = 15  # Increased from 5 to 15 seconds to reduce flickering
    FRAME_WIDTH = 640
    FRAME_HEIGHT = 480
    FPS = 15
    MOTION_DETECTION_INTERVAL = 3  # Only check motion every N frames
    PERSON_DETECTION_MIN_FEATURES = 3  # Minimum number of pose landmarks needed to consider a person detection valid
    CONSECUTIVE_MOTION_FRAMES_THRESHOLD = 3  # Number of consecutive frames with motion to consider it reliable

# File Manager
class FileManager:
    @staticmethod
    def ensure_captured_images_dir():
        os.makedirs("captured_images", exist_ok=True)
        
    @staticmethod
    def save_captured_image(frame):
        FileManager.ensure_captured_images_dir()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = f"captured_images/capture_{timestamp}.jpg"
        cv2.imwrite(filepath, frame)
        return filepath

# Global State Management
class SystemState:
    def __init__(self):
        self.people_count = 0
        self.motion_detected = False
        self.last_detection_time = time.time()
        self.manual_override_time = None
        self.light_state = False
        self.switch_state = False
        self.manual_mode = False
        self.last_notification_time = 0
        self.send_notifications = True
        self.current_frame = None
        self.bot_started = False
        self.remote_control = False
        self.auto_mode = True  # Default mode is Auto
        self.frame_count = 0
        self.last_error_time = 0
        self.application = None
        self.running = True
        self.consecutive_motion_frames = 0  # Track consecutive frames with motion
        self.motion_detected_count = 0  # Count of recent motion detections
        self.last_reliable_motion_time = 0  # Last time reliable motion was detected
        
    def update_detection_time(self):
        self.last_detection_time = time.time()
        
    def update_notification_time(self):
        self.last_notification_time = time.time()

system_state = SystemState()

# GPIO Manager
class GPIOManager:
    @staticmethod
    def setup():
        GPIO.setwarnings(False)
        GPIO.setmode(GPIO.BCM)
        GPIO.setup(Config.RELAY_PIN_1, GPIO.OUT)
        GPIO.setup(Config.RELAY_PIN_2, GPIO.OUT)
        GPIO.setup(Config.SWITCH_PIN, GPIO.IN, pull_up_down=GPIO.PUD_UP)
        GPIO.setup(Config.LED_PIN, GPIO.OUT)
        GPIOManager.turn_off_all()
        
    @staticmethod
    def cleanup():
        try:
            GPIO.cleanup()
        except Exception as e:
            logger.error(f"Error in GPIO cleanup: {e}")
        
    @staticmethod
    def turn_off_all():
        # Set both relay pins to HIGH (off)
        GPIO.output(Config.RELAY_PIN_1, GPIO.HIGH)
        GPIO.output(Config.RELAY_PIN_2, GPIO.HIGH)
        GPIO.output(Config.LED_PIN, GPIO.LOW)
        
    @staticmethod
    def check_switch_state():
        return GPIO.input(Config.SWITCH_PIN) == GPIO.HIGH
        
    @staticmethod
    def control_lights(state):
        # Turn on/off both relay pins
        # LOW turns on the relay (normally closed)
        GPIO.output(Config.RELAY_PIN_1, GPIO.LOW if state else GPIO.HIGH)
        GPIO.output(Config.RELAY_PIN_2, GPIO.LOW if state else GPIO.HIGH)
        # LED is direct (HIGH = on)
        GPIO.output(Config.LED_PIN, GPIO.HIGH if state else GPIO.LOW)

# Person Tracker
class PersonTracker:
    def __init__(self):
        self.next_person_id = 0
        self.persons = {}
        self.movement_history = {}
        
    def register(self, center, confidence):
        self.persons[self.next_person_id] = {
            "center": center, 
            "disappeared": 0,
            "confidence": confidence
        }
        self.movement_history[self.next_person_id] = deque(maxlen=Config.HISTORY_LENGTH)
        self.movement_history[self.next_person_id].append(center)
        self.next_person_id += 1

    def deregister(self, person_id):
        if person_id in self.persons:
            del self.persons[person_id]
        if person_id in self.movement_history:
            del self.movement_history[person_id]

    def update(self, detections):
        # Update disappeared counter for all existing persons
        for person_id in list(self.persons.keys()):
            self.persons[person_id]["disappeared"] += 1
            if self.persons[person_id]["disappeared"] > Config.MAX_DISAPPEARED:
                self.deregister(person_id)

        # If no detections, return current persons
        if not detections:
            return self.persons

        # If no existing persons, register all new detections
        if not self.persons:
            for center, confidence in detections:
                if confidence >= Config.PERSON_CONFIDENCE_THRESHOLD:
                    self.register(center, confidence)
            return self.persons

        # Calculate cost matrix for Hungarian algorithm
        person_ids = list(self.persons.keys())
        person_centers = [self.persons[i]["center"] for i in person_ids]
        
        distance_matrix = np.zeros((len(person_ids), len(detections)))
        for i, person_center in enumerate(person_centers):
            for j, (new_center, _) in enumerate(detections):
                distance_matrix[i, j] = np.linalg.norm(np.array(person_center) - np.array(new_center))

        # Use Hungarian algorithm to find optimal assignment
        row_ind, col_ind = linear_sum_assignment(distance_matrix)

        # Update tracked persons with new detections
        for i, j in zip(row_ind, col_ind):
            person_id = person_ids[i]
            new_center, confidence = detections[j]
            distance = distance_matrix[i, j]
            
            if distance < Config.MAX_DISTANCE:
                self.persons[person_id]["center"] = new_center
                self.persons[person_id]["disappeared"] = 0
                self.persons[person_id]["confidence"] = confidence
                self.movement_history[person_id].append(new_center)

        # Register unmatched detections as new persons
        unmatched_detections = set(range(len(detections))) - set(col_ind)
        for j in unmatched_detections:
            center, confidence = detections[j]
            if confidence >= Config.PERSON_CONFIDENCE_THRESHOLD:
                self.register(center, confidence)

        return self.persons

    def draw_tracks(self, frame):
        # Draw movement history and current position for all tracked persons
        for person_id, history in self.movement_history.items():
            if len(history) < 2:
                continue
                
            # Draw trajectory line
            points = np.array(list(history), dtype=np.int32)
            cv2.polylines(frame, [points], False, (0, 255, 255), 2)
            
            # Draw current position and ID if person is still being tracked
            if person_id in self.persons:
                center = self.persons[person_id]["center"]
                confidence = self.persons[person_id]["confidence"]
                cv2.circle(frame, center, 5, (0, 255, 0), -1)
                cv2.putText(frame, f"ID: {person_id} ({confidence:.2f})", 
                           (center[0] + 10, center[1] - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        return frame

# Detection System
class DetectionSystem:
    def __init__(self):
        # Initialize pose detection with higher sensitivity
        self.pose = mp_pose.Pose(
            min_detection_confidence=0.5,  # Lower threshold to detect more poses
            min_tracking_confidence=0.5,
            model_complexity=1,
            static_image_mode=False
        )
        self.person_tracker = PersonTracker()
        
        # Initialize motion detection with less sensitive parameters to reduce false detections
        self.background_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=500,  # Increased from 300 to 500 for more stable background model
            varThreshold=60,  # Increased from 40 to 60 to reduce sensitivity
            detectShadows=False  # Disable shadow detection for better performance
        )
        self.frame_buffer = deque(maxlen=5)
        self.last_motion_time = 0
        self.motion_frame_history = deque(maxlen=10)  # Store history of motion detection results
        
    def detect_people(self, frame):
        # Convert to RGB for MediaPipe
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # Make the frame non-writeable to improve performance
        rgb_frame.flags.writeable = False
        results = self.pose.process(rgb_frame)
        # Make the frame writeable again
        rgb_frame.flags.writeable = True
        
        detections = []
        
        if results.pose_landmarks:
            # Use more landmarks for better tracking
            landmarks_to_check = [
                mp_pose.PoseLandmark.NOSE,
                mp_pose.PoseLandmark.LEFT_SHOULDER,
                mp_pose.PoseLandmark.RIGHT_SHOULDER,
                mp_pose.PoseLandmark.LEFT_EYE,
                mp_pose.PoseLandmark.RIGHT_EYE,
                mp_pose.PoseLandmark.LEFT_HIP,
                mp_pose.PoseLandmark.RIGHT_HIP
            ]
            
            h, w, _ = frame.shape
            valid_points = 0
            
            for landmark in landmarks_to_check:
                lm = results.pose_landmarks.landmark[landmark]
                # Only consider landmarks with good visibility
                if lm.visibility > Config.PERSON_CONFIDENCE_THRESHOLD:
                    valid_points += 1
                    point = (int(lm.x * w), int(lm.y * h))
                    detections.append((point, lm.visibility))
            
            # Only draw pose if enough valid landmarks were detected
            if valid_points >= Config.PERSON_DETECTION_MIN_FEATURES:
                mp_drawing.draw_landmarks(
                    frame, 
                    results.pose_landmarks, 
                    mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()
                )
                
        # Update person tracker and get current tracking state
        persons = self.person_tracker.update(detections)
        
        # Count people with high confidence
        high_confidence_people = sum(
            1 for p in persons.values() 
            if p["confidence"] >= Config.PERSON_CONFIDENCE_THRESHOLD
        )
        
        # Only update people count if it changed
        if system_state.people_count != high_confidence_people:
            system_state.people_count = high_confidence_people
            if high_confidence_people > 0:
                logger.debug(f"Detected {high_confidence_people} people with high confidence")
        
        # Draw tracks on the frame
        frame = self.person_tracker.draw_tracks(frame)
        return frame
        
    def detect_motion(self, frame):
        # Only perform motion detection on some frames to save processing
        if system_state.frame_count % Config.MOTION_DETECTION_INTERVAL != 0:
            return frame, None
            
        # Add frame to buffer
        self.frame_buffer.append(frame.copy())
        
        # Only process if we have enough frames in buffer
        if len(self.frame_buffer) < 3:
            system_state.motion_detected = False
            return frame, np.zeros_like(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))
            
        # Get frames for motion detection
        current_frame = self.frame_buffer[-1]
        prev_frame = self.frame_buffer[-2]
        
        # Convert to grayscale and blur
        gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (21, 21), 0)
        
        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
        prev_gray = cv2.GaussianBlur(prev_gray, (21, 21), 0)
        
        # Compute absolute difference
        frame_diff = cv2.absdiff(prev_gray, gray)
        
        # Apply background subtraction for longer-term changes
        fg_mask = self.background_subtractor.apply(gray)
        
        # Combine both methods
        combined_mask = cv2.bitwise_or(frame_diff, fg_mask)
        
        # Threshold
        _, thresh = cv2.threshold(combined_mask, 25, 255, cv2.THRESH_BINARY)
        
        # Noise removal - more aggressive to reduce false positives
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, np.ones((7, 7), np.uint8))  # Increased kernel size
        # Use proper kernel for dilation to avoid errors
        kernel = np.ones((3, 3), np.uint8)
        thresh = cv2.dilate(thresh, kernel, iterations=2)
        
        # Find contours
        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Reset motion state
        prev_motion_state = system_state.motion_detected
        motion_detected_this_frame = False
        
        # Only consider motion if it's not in cooldown period
        current_time = time.time()
        if current_time - self.last_motion_time > Config.MOTION_COOLDOWN:
            # Calculate total motion area and motion regions
            motion_regions = []
            total_motion_area = 0
            significant_contours = 0
            
            for contour in contours:
                # Calculate contour area
                contour_area = cv2.contourArea(contour)
                
                # Only consider large enough contours
                if contour_area > Config.MOTION_MIN_AREA:
                    total_motion_area += contour_area
                    significant_contours += 1
                    
                    # Get bounding rectangle
                    (x, y, w, h) = cv2.boundingRect(contour)
                    motion_regions.append((x, y, w, h))
                    
                    # Draw rectangle on frame
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
            
            # Frame area calculations
            frame_area = frame.shape[0] * frame.shape[1]
            motion_percentage = (total_motion_area / frame_area) * 100
            
            # Log motion details for debugging without triggering motion state
            if significant_contours > 0 and Config.DEBUG_MODE:
                logger.debug(f"Motion candidates: {significant_contours} contours, {total_motion_area} px ({motion_percentage:.1f}% of frame)")
                
            # Much stricter conditions to avoid false positives entirely
            if (total_motion_area > Config.MOTION_MIN_AREA and 
                total_motion_area < (frame_area * 0.25) and  # Reduced from 0.3 to 0.25
                significant_contours >= 2 and
                motion_percentage > 1.0 and motion_percentage < 20):  # Adjusted thresholds
                
                motion_detected_this_frame = True
                
                # Add to motion frame history for consistency check
                self.motion_frame_history.append(True)
                
                # Add motion indicator text
                cv2.putText(frame, f"Motion Detected ({significant_contours})", (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                # Log motion detection
                if not prev_motion_state:
                    logger.debug(f"Motion detected, area: {total_motion_area}, contours: {significant_contours}, regions: {len(motion_regions)}")
            else:
                self.motion_frame_history.append(False)
        else:
            self.motion_frame_history.append(False)
            
        # Count consecutive motion frames
        consecutive_motion_frames = 0
        for is_motion in reversed(self.motion_frame_history):
            if is_motion:
                consecutive_motion_frames += 1
            else:
                break
                
        # Update system state based on consistent motion detection
        if consecutive_motion_frames >= Config.CONSECUTIVE_MOTION_FRAMES_THRESHOLD:
            system_state.consecutive_motion_frames = consecutive_motion_frames
            system_state.motion_detected = True
            
            if not prev_motion_state:
                system_state.last_reliable_motion_time = current_time
                logger.info(f"Reliable motion detected after {consecutive_motion_frames} consecutive frames")
                
            # Reset timer only for reliable motion
            if motion_detected_this_frame:
                self.last_motion_time = current_time
        else:
            system_state.consecutive_motion_frames = consecutive_motion_frames
            system_state.motion_detected = False
        
        return frame, thresh
        
    def cleanup(self):
        self.pose.close()

# Light Controller
class LightController:
    @staticmethod
    def control_light():
        # Read hardware switch state for override
        current_switch = GPIOManager.check_switch_state()

        # Check if switch state changed
        if current_switch != system_state.switch_state:
            system_state.switch_state = current_switch
            system_state.manual_override_time = time.time()
            
            if not current_switch:
                # Switch OFF = Manual mode + Lights OFF
                system_state.manual_mode = True
                system_state.light_state = False
                system_state.auto_mode = False
                if Config.DEBUG_MODE:
                    logger.info("[Switch OFF] Manual mode activated. Light OFF.")
            else:
                # Switch ON = Auto mode
                system_state.manual_mode = False
                system_state.auto_mode = True
                if Config.DEBUG_MODE:
                    logger.info("[Switch ON] Auto mode activated.")

        # If in auto mode, control light based on detection
        if system_state.auto_mode:
            # Only turn on lights if detections are reliable
            current_time = time.time()
            
            # Turn on if people detected with confidence
            if system_state.people_count > 0:
                if not system_state.light_state and Config.DEBUG_MODE:
                    logger.info(f"[Person Detection] {system_state.people_count} people detected. Turning light ON.")
                system_state.light_state = True
                system_state.update_detection_time()
            # Turn on if motion detected and it's reliable (not a false positive)
            elif system_state.motion_detected:
                # Extra verification to make sure it's not a false positive
                motion_detected_reliably = False
                
                # Consider motion reliable if:
                # 1. We've seen consistent motion across multiple frames
                if system_state.consecutive_motion_frames >= Config.CONSECUTIVE_MOTION_FRAMES_THRESHOLD:
                    motion_detected_reliably = True
                # 2. We've seen people recently (within last 30 seconds)
                elif current_time - system_state.last_detection_time < 30:
                    motion_detected_reliably = True
                
                if motion_detected_reliably:
                    if not system_state.light_state and Config.DEBUG_MODE:
                        logger.info("[Motion Detection] Verified motion detected. Turning light ON.")
                    system_state.light_state = True
                    system_state.update_detection_time()
                else:
                    logger.debug("Motion detected but failed reliability check.")
            # Check timeout for turning off - only turn off if no detection for the timeout period
            elif system_state.light_state and (current_time - system_state.last_detection_time) > Config.AUTO_LIGHT_TIMEOUT:
                if Config.DEBUG_MODE:
                    logger.info(f"[Timeout] No detection for {Config.AUTO_LIGHT_TIMEOUT}s. Turning light OFF.")
                system_state.light_state = False
        
        # Update hardware light state
        GPIOManager.control_lights(system_state.light_state)

# Notification Manager
class NotificationManager:
    @staticmethod
    async def send_detection_notification():
        if system_state.current_frame is None or (system_state.people_count == 0 and not system_state.motion_detected):
            return
        
        # Check cooldown
        current_time = time.time()
        if current_time - system_state.last_notification_time < Config.NOTIFICATION_COOLDOWN:
            return
            
        system_state.last_notification_time = current_time
        
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # Create a copy of the frame
            frame_copy = system_state.current_frame.copy()
            cv2.putText(frame_copy, f"Time: {timestamp}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Create notification message
            if system_state.people_count > 0:
                cv2.putText(frame_copy, f"People detected: {system_state.people_count}", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                message = f"ALERT: {system_state.people_count} person(s) detected at {timestamp}"
            else:
                cv2.putText(frame_copy, "Motion detected", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                message = f"ALERT: Motion detected at {timestamp}"
            
            # Save image
            filepath = FileManager.save_captured_image(frame_copy)
            logger.info(f"Detection image saved to {filepath}")
            
            # Send notification via Telegram
            if system_state.application and system_state.send_notifications:
                # Convert image to bytes
                _, buffer = cv2.imencode(".jpg", frame_copy)
                image_data = io.BytesIO(buffer)
                
                # Get list of chat IDs to notify
                target_chats = Config.ALLOWED_CHAT_IDS
                if not target_chats:
                    # If no specific chats configured, use first admin
                    admins = await system_state.application.bot.get_chat_administrators(chat_id=Config.TELEGRAM_TOKEN.split(":")[0])
                    if admins:
                        target_chats = [admins[0].user.id]
                    else:
                        logger.warning("No target chats for notification")
                        return
                
                # Send to all target chats
                for chat_id in target_chats:
                    try:
                        await system_state.application.bot.send_photo(
                            chat_id=chat_id,
                            photo=image_data,
                            caption=message
                        )
                    except Exception as e:
                        logger.error(f"Failed to send notification to {chat_id}: {e}")
                
        except Exception as e:
            logger.error(f"Error sending notification: {e}")

# Telegram Bot
class TelegramBot:
    def __init__(self):
        self.application = None
        
    async def start(self):
        """Start and initialize the Telegram bot"""
        max_retries = 3
        retry_delay = 5  # seconds
        
        for attempt in range(max_retries):
            try:
                # Create the Telegram application with timeouts
                self.application = Application.builder().token(Config.TELEGRAM_TOKEN).build()
                system_state.application = self.application
                
                # Setup command handlers
                self.application.add_handler(CommandHandler("start", self.handle_start))
                self.application.add_handler(CommandHandler("help", self.handle_help))
                self.application.add_handler(CommandHandler("status", self.handle_status))
                self.application.add_handler(CommandHandler("light_on", self.handle_light_on))
                self.application.add_handler(CommandHandler("light_off", self.handle_light_off))
                self.application.add_handler(CommandHandler("auto_mode", self.handle_auto_mode))
                self.application.add_handler(CommandHandler("capture", self.handle_capture))
                
                # Setup callback handler for inline buttons
                self.application.add_handler(CallbackQueryHandler(self.handle_button_callback))
                
                # Setup message handler for text messages
                self.application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text_message))
                
                # Setup error handler
                self.application.add_error_handler(self.handle_error)
                
                # Start the bot
                await self.application.initialize()
                await self.application.start()
                await self.application.updater.start_polling(allowed_updates=Update.ALL_TYPES)
                
                # Log bot information
                bot_info = await self.application.bot.get_me()
                logger.info(f"Telegram bot started. Username: @{bot_info.username}")
                system_state.bot_started = True
                
                # Keep the bot running
                while system_state.running:
                    await asyncio.sleep(1)
                    
                # Clean shutdown
                await self.application.stop()
                
            except Exception as e:
                logger.error(f"Error starting Telegram bot (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    continue
                system_state.bot_started = False
                if self.application:
                    try:
                        await self.application.stop()
                    except:
                        pass
                return
    
    async def handle_start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /start command"""
        if update.effective_chat is None:
            return
            
        chat_id = update.effective_chat.id
        
        # Check if user is allowed (if ALLOWED_CHAT_IDS is set)
        if Config.ALLOWED_CHAT_IDS and chat_id not in Config.ALLOWED_CHAT_IDS:
            await context.bot.send_message(
                chat_id=chat_id,
                text="Sorry, you are not authorized to use this bot."
            )
            return
        
        # Create inline keyboard
        keyboard = [
            [
                InlineKeyboardButton("Status", callback_data="status"),
                InlineKeyboardButton("Capture", callback_data="capture")
            ],
            [
                InlineKeyboardButton("Light ON", callback_data="light_on"),
                InlineKeyboardButton("Light OFF", callback_data="light_off")
            ],
            [
                InlineKeyboardButton("Auto Mode", callback_data="auto_mode")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await context.bot.send_message(
            chat_id=chat_id,
            text="Welcome to Smart Lighting Control System!\n\n"
                 "ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Use 'Light ON' to manually turn on lights\n"
                 "ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Use 'Light OFF' to manually turn off lights\n"
                 "ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Use 'Auto Mode' to enable automatic control\n"
                 "ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Use 'Status' to check the current system state\n"
                 "ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Use 'Capture' to view the current camera feed",
            reply_markup=reply_markup
        )
    
    async def handle_help(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /help command"""
        help_text = """
Smart Lighting Control System

Available Commands:
/start - Show main menu with control buttons
/help - Show this help message
/status - Show current system status
/light_on - Turn lights ON manually
/light_off - Turn lights OFF manually
/auto_mode - Enable automatic light control based on detection
/capture - Capture and send current camera image

System Modes:
ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Auto Mode: Lights turn ON when people or motion are detected, and turn OFF after timeout period
ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Manual Mode: Lights stay in fixed state (ON or OFF) until mode is changed

Hardware Controls:
ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢ Physical switch can be used to override and toggle between Auto/Manual modes
"""
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=help_text,
            parse_mode='Markdown'
        )
    
    async def handle_status(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /status command"""
        status_text = f"""
System Status:
- People detected: {system_state.people_count}
- Motion detected: {'Yes' if system_state.motion_detected else 'No'}
- Consecutive motion frames: {system_state.consecutive_motion_frames}
- Light state: {'ON' if system_state.light_state else 'OFF'}
- Mode: {'Auto' if system_state.auto_mode else 'Manual'}
- Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=status_text,
            parse_mode='Markdown'
        )
    
    async def handle_light_on(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /light_on command - Turn ON lights manually"""
        # Disable auto mode, enable manual mode, turn on lights
        system_state.auto_mode = False
        system_state.manual_mode = True
        system_state.light_state = True
        GPIOManager.control_lights(True)
        
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Lights turned ON manually.\nSystem is now in manual mode."
        )
    
    async def handle_light_off(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /light_off command - Turn OFF lights manually"""
        # Disable auto mode, enable manual mode, turn off lights
        system_state.auto_mode = False
        system_state.manual_mode = True
        system_state.light_state = False
        GPIOManager.control_lights(False)
        
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Lights turned OFF manually.\nSystem is now in manual mode."
        )
    
    async def handle_auto_mode(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /auto_mode command - Enable automatic control"""
        # Enable auto mode, disable manual mode
        system_state.auto_mode = True
        system_state.manual_mode = False
        
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="ÃƒÂ¢Ã…â€œÃ¢â‚¬Â¦ Automatic mode activated.\nLights will turn ON when motion or people are detected."
        )
    
    async def handle_capture(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for /capture command - Send current camera image"""
        if system_state.current_frame is None:
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text="No camera frame available."
            )
            return
        
        try:
            # Create a copy of the frame
            frame_copy = system_state.current_frame.copy()
            
            # Add info overlay
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cv2.putText(frame_copy, f"Time: {timestamp}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame_copy, f"People: {system_state.people_count}", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame_copy, f"Motion: {'Yes' if system_state.motion_detected else 'No'} ({system_state.consecutive_motion_frames})", (10, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame_copy, f"Lights: {'ON' if system_state.light_state else 'OFF'}", (10, 120), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame_copy, f"Mode: {'Auto' if system_state.auto_mode else 'Manual'}", (10, 150), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Convert to JPEG bytes
            _, buffer = cv2.imencode(".jpg", frame_copy)
            image_data = io.BytesIO(buffer)
            
            # Send the image
            await context.bot.send_photo(
                chat_id=update.effective_chat.id,
                photo=image_data,
                caption=f"Current view - People: {system_state.people_count}, Motion: {'Yes' if system_state.motion_detected else 'No'}, Lights: {'ON' if system_state.light_state else 'OFF'}"
            )
            
            # Save image to file system
            FileManager.save_captured_image(frame_copy)
            
        except Exception as e:
            logger.error(f"Error capturing image: {e}")
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text=f"Error capturing image: {str(e)}"
            )
    
    async def handle_button_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for inline keyboard button callbacks"""
        query = update.callback_query
        await query.answer()
        
        # Route to appropriate handler based on callback data
        if query.data == "status":
            await self.handle_status(update, context)
        elif query.data == "light_on":
            await self.handle_light_on(update, context)
        elif query.data == "light_off":
            await self.handle_light_off(update, context)
        elif query.data == "auto_mode":
            await self.handle_auto_mode(update, context)
        elif query.data == "capture":
            await self.handle_capture(update, context)
    
    async def handle_text_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handler for text messages - Show menu"""
        await self.handle_start(update, context)
    
    async def handle_error(self, update, context):
        """Error handler"""
        logger.error(f"Update {update} caused error: {context.error}")
        try:
            # Log detailed error information
            logger.error(f"Error details: {context.error.__class__.__name__}: {context.error}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            
            # Only notify about errors every 5 minutes to prevent spam
            current_time = time.time()
            if current_time - system_state.last_error_time > 300:
                system_state.last_error_time = current_time
                
                if update and update.effective_chat:
                    await context.bot.send_message(
                        chat_id=update.effective_chat.id,
                        text="An error occurred. Please try again later."
                    )
        except:
            pass

class CameraProcess:
    def __init__(self):
        try:
            self.picam2 = Picamera2()
            config = self.picam2.create_video_configuration(main={"size": (640, 480)})
            self.picam2.configure(config)
            logger.info("Camera initialized successfully.")
        except Exception as e:
            logger.error(f"Failed to initialize camera: {e}")
            raise

    def initialize(self):
        logger.info("Initializing detection system...")
        self.detection_system = DetectionSystem()

        logger.info("Starting camera...")
        self.picam2.start()
        time.sleep(1)

    def run(self):
        try:
            self.initialize()

            fps_start_time = time.time()
            fps_counter = 0
            fps = 0

            while system_state.running:
                frame = self.picam2.capture_array()
                system_state.current_frame = frame.copy()

                # Detection logic
                frame = self.detection_system.detect_people(frame)
                frame, motion_mask = self.detection_system.detect_motion(frame)

                # FPS calculation
                fps_counter += 1
                elapsed = time.time() - fps_start_time
                if elapsed >= 1:
                    fps = fps_counter / elapsed
                    fps_counter = 0
                    fps_start_time = time.time()

                cv2.putText(frame, f"FPS: {fps:.1f}", (10, 20), cv2.FONT_HERSHEY_SIMPLEX,
                            0.5, (0, 255, 0), 2)

                # Display only in main thread
                if Config.DEBUG_MODE and threading.current_thread() is threading.main_thread():
                    try:
                        cv2.imshow("Smart Lighting System", frame)
                        if motion_mask is not None:
                            cv2.imshow("Motion Detection", motion_mask)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            system_state.running = False
                            break
                    except cv2.error as e:
                        logger.warning(f"cv2.imshow failed: {e}")
                else:
                    logger.debug("cv2.imshow skipped (not main thread)")

        except Exception as e:
            logger.error(f"Error in camera process: {e}")
            logger.error(traceback.format_exc())
        finally:
            self.cleanup()

    def cleanup(self):
        self.picam2.close()
        if hasattr(self, "detection_system"):
            self.detection_system.cleanup()
        cv2.destroyAllWindows()
        logger.info("Camera resources cleaned up")

    
              


                
def main():
    logger.info("====== Smart Lighting System Starting ======")

    def signal_handler(sig, frame):
        logger.info("Shutdown signal received")
        system_state.running = False

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        FileManager.ensure_captured_images_dir()
        GPIOManager.setup()

         # Camera runs in MAIN thread (so imshow works!)
        camera_process = CameraProcess()
        camera_process.run()

        # Start Telegram bot in background
        def run_bot():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            telegram_bot = TelegramBot()
            loop.run_until_complete(telegram_bot.start())

        bot_thread = threading.Thread(target=run_bot)
        bot_thread.daemon = True
        bot_thread.start()

       

    except Exception as e:
        logger.error(f"Error in main: {e}")
        logger.error(traceback.format_exc())
    finally:
        GPIOManager.cleanup()
        system_state.running = False
        logger.info("System shutdown complete")


if __name__ == "__main__":
    main()

